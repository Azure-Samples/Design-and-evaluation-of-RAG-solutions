{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-rank chunks and generate answers\n",
    "\n",
    "This code demonstrate how to evaluate chunks in parallel generating the percentage of similarity with the question and the answer (part of text in the chunk more appropiate to answer the question).\n",
    "\n",
    "The output is the chunks more relevant to answer the question and the answer generated with those chunks.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "+ An Azure subscription, with [access to Azure OpenAI](https://aka.ms/oai/access).\n",
    "+ An Azure OpenAI service with the service name and an API key.\n",
    "+ A deployment of the text-embedding-ada-002 embedding model on the Azure OpenAI Service.\n",
    "+ An Azure AI Search service with the end-point, API Key and the index name to create.\n",
    "\n",
    "We used Python 3.12.5, [Visual Studio Code with the Python extension](https://code.visualstudio.com/docs/python/python-tutorial), and the [Jupyter extension](https://marketplace.visualstudio.com/items?itemName=ms-toolsai.jupyter) to test this example.\n",
    "\n",
    "### Set up a Python virtual environment in Visual Studio Code\n",
    "\n",
    "1. Open the Command Palette (Ctrl+Shift+P).\n",
    "1. Search for **Python: Create Environment**.\n",
    "1. Select **Venv**.\n",
    "1. Select a Python interpreter. Choose 3.10 or later.\n",
    "\n",
    "It can take a minute to set up. If you run into problems, see [Python environments in VS Code](https://code.visualstudio.com/docs/python/environments)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install openai\n",
    "! pip install azure-search-documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages and create AOAI client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents import SearchClient\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "from rag_utils import calculate_rank, semantic_hybrid_search_with_filter, get_filtered_chunks, generate_answer\n",
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# AZURE AI SEARCH\n",
    "ai_search_endpoint = os.environ[\"SEARCH_SERVICE_ENDPOINT\"]\n",
    "ai_search_apikey = os.environ[\"SEARCH_SERVICE_QUERY_KEY\"]\n",
    "ai_search_index_name = os.environ[\"SEARCH_INDEX_NAME\"]\n",
    "ai_search_credential = AzureKeyCredential(ai_search_apikey)\n",
    "# Create Azure AI Search client\n",
    "ai_search_client = SearchClient(endpoint=ai_search_endpoint, index_name=ai_search_index_name, credential=ai_search_credential)\n",
    "\n",
    "aoai_api_version = '2024-02-15-preview'\n",
    "\n",
    "# AOAI FOR ANSWER GENERATION\n",
    "aoai_answer_endpoint = os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
    "aoai_answer_apikey = os.environ[\"AZURE_OPENAI_API_KEY\"]\n",
    "aoai_answer_model_name = os.environ[\"AZURE_OPENAI_DEPLOYMENT_NAME\"]\n",
    "# Create AOAI client for answer generation\n",
    "aoai_answer_client = AzureOpenAI(\n",
    "    azure_deployment=aoai_answer_model_name,\n",
    "    api_version=aoai_api_version,\n",
    "    azure_endpoint=aoai_answer_endpoint,\n",
    "    api_key=aoai_answer_apikey\n",
    ")\n",
    "\n",
    "# AZURE OPENAI FOR RERANKING\n",
    "aoai_rerank_endpoint = os.environ[\"AZURE_OPENAI_RERANK_ENDPOINT\"]\n",
    "azure_openai_rerank_key = os.environ[\"AZURE_OPENAI_RERANK_API_KEY\"]\n",
    "rerank_model_name = os.environ[\"AZURE_OPENAI_RERANK_DEPLOYMENT_NAME\"]\n",
    "# Create AOAI client for reranking\n",
    "aoai_rerank_client = AzureOpenAI(\n",
    "    azure_deployment=rerank_model_name,\n",
    "    api_version=aoai_api_version,\n",
    "    azure_endpoint=aoai_rerank_endpoint,\n",
    "    api_key=azure_openai_rerank_key\n",
    ")\n",
    "\n",
    "# AZURE OPENAI FOR EMBEDDING\n",
    "aoai_embedding_endpoint = os.environ[\"AZURE_OPENAI_EMBEDDING_ENDPOINT\"]\n",
    "azure_openai_embedding_key = os.environ[\"AZURE_OPENAI_EMBEDDING_API_KEY\"]\n",
    "embedding_model_name = os.environ[\"AZURE_OPENAI_EMBEDDING_NAME_ADA\"]\n",
    "# Create AOAI client for embedding creation (ADA)\n",
    "aoai_embedding_client = AzureOpenAI(\n",
    "    azure_deployment=embedding_model_name,\n",
    "    api_version=aoai_api_version,\n",
    "    azure_endpoint=aoai_embedding_endpoint,\n",
    "    api_key=azure_openai_embedding_key\n",
    ")\n",
    "\n",
    "# CONSTANTS\n",
    "MAX_DOCS = 20 # Maximum number of documents to retrieve in the query\n",
    "EMBEDDING_FIELDS = \"embeddingTitle, embeddingContent\" # Vector fields to search for\n",
    "SELECT_FIELDS=[\"id\", \"title\", \"content\"] # Fields to retrieve in the search\n",
    "QUERY_LANGUAGE=\"es-es\" # Query language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def show_results(results, query, rerank=False):\n",
    "    #print(f'query: {query}, num results: {results.get_count()}')\n",
    "    data = []\n",
    "    for i, result in enumerate(results):\n",
    "        if rerank:\n",
    "            confidence, answer = calculate_rank(aoai_rerank_client, rerank_model_name, result['title'] + \". \" + result['content'], query)\n",
    "            response = f'confidence: {confidence}, answer: {answer}'\n",
    "        else:\n",
    "            response = 'n/a'\n",
    "\n",
    "        data.append(\n",
    "            [result[\"id\"],\n",
    "             result[\"title\"],\n",
    "             result[\"content\"], \n",
    "             result[\"@search.score\"],\n",
    "             response\n",
    "            ]\n",
    "        )\n",
    "        if i + 1 == MAX_DOCS: break # Stops at the maximum number of documents\n",
    "\n",
    "    return pd.DataFrame(data, columns=[\"id\", \"title\", \"content\", \"@search.score\", \"rerank\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"¿CÓMO DESISTIR DEL RELOJ?\"\n",
    "results = semantic_hybrid_search_with_filter(ai_search_client, query, aoai_embedding_client, embedding_model_name, EMBEDDING_FIELDS, MAX_DOCS, SELECT_FIELDS, QUERY_LANGUAGE)\n",
    "show_results(results, query, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Patrocinio de Eventos\"\n",
    "results = semantic_hybrid_search_with_filter(ai_search_client, query, aoai_embedding_client, embedding_model_name, EMBEDDING_FIELDS, MAX_DOCS, SELECT_FIELDS, QUERY_LANGUAGE)\n",
    "chunks = get_filtered_chunks(aoai_rerank_client, rerank_model_name, results, query, MAX_DOCS)\n",
    "if len(chunks) > 0:\n",
    "    # Generate answer using the complete chunks\n",
    "    answer = generate_answer(aoai_answer_client, aoai_answer_model_name, chunks, query, 'content')\n",
    "else:\n",
    "    answer = 'There it not content to generate the answer'\n",
    "print(f'\\nANSWER: {answer}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Patrocinio de Eventos\"\n",
    "results = semantic_hybrid_search_with_filter(ai_search_client, query, aoai_embedding_client, embedding_model_name, EMBEDDING_FIELDS, MAX_DOCS, SELECT_FIELDS, QUERY_LANGUAGE)\n",
    "chunks = get_filtered_chunks(aoai_rerank_client, rerank_model_name, results, query, MAX_DOCS)\n",
    "if len(chunks) > 0:\n",
    "    # Generate answer using the 'answer' generated by the re-ranker\n",
    "    answer = generate_answer(aoai_answer_client, aoai_answer_model_name, chunks, query, 'answer')\n",
    "else:\n",
    "    answer = 'There it not content to generate the answer'\n",
    "print(f'\\nANSWER: {answer}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
