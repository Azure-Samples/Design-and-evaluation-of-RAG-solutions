{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify content in markdown format in three categories, to detect low-value content\n",
    "\n",
    "This code demonstrate how to classify markdown content in three categories:\n",
    "+ TABLE-ONLY: If there is only a table with no context nor description.\n",
    "+ TEXT-ONLY: if there is no table at all.\n",
    "+ TABLE-WITH-CONTEXT: if there is a table with context or description\n",
    "\n",
    "The output is one those three categories and the explaination of the reason to classify the content on it.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "+ An Azure subscription, with [access to Azure OpenAI](https://aka.ms/oai/access).\n",
    "+ An Azure OpenAI service with the service name and an API key.\n",
    "+ A deployment of GPT-4o in the on the Azure OpenAI Service.\n",
    "\n",
    "We used Python 3.12.5, [Visual Studio Code with the Python extension](https://code.visualstudio.com/docs/python/python-tutorial), and the [Jupyter extension](https://marketplace.visualstudio.com/items?itemName=ms-toolsai.jupyter) to test this example.\n",
    "\n",
    "### Set up a Python virtual environment in Visual Studio Code\n",
    "\n",
    "1. Open the Command Palette (Ctrl+Shift+P).\n",
    "1. Search for **Python: Create Environment**.\n",
    "1. Select **Venv**.\n",
    "1. Select a Python interpreter. Choose 3.10 or later.\n",
    "\n",
    "It can take a minute to set up. If you run into problems, see [Python environments in VS Code](https://code.visualstudio.com/docs/python/environments)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages and create AOAI client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "from rag_utils import load_files, call_aoai\n",
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# AOAI FOR CLASSIFICATION\n",
    "aoai_endpoint = os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
    "aoai_apikey = os.environ[\"AZURE_OPENAI_API_KEY\"]\n",
    "aoai_model_name = os.environ[\"AZURE_OPENAI_DEPLOYMENT_NAME\"]\n",
    "# Create AOAI client\n",
    "aoai_api_version = '2024-02-15-preview'\n",
    "aoai_client = AzureOpenAI(\n",
    "    azure_deployment=aoai_model_name,\n",
    "    api_version=aoai_api_version,\n",
    "    azure_endpoint=aoai_endpoint,\n",
    "    api_key=aoai_apikey\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify sections in three categories:\n",
    "### TABLE-ONLY, TABLE-WITH-CONTEXT and TEXT-ONLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_with_gpt4o(text):\n",
    "\n",
    "    system_prompt = \"You have to detect in this document a table and identify if there is any context or description that describes the meaning of the table. The context could be inside or outside of the table. The context will be a sentence with several or paragraph. If there is only a table with no context nor description return 'TABLE-ONLY', if there is no table at all return 'TEXT-ONLY', and if there is a table with context or description return 'TABLE-WITH-CONTEXT'. Add the explaination of your decision. Your answer must be with this format, one line per document: Type, Explaination.\"\n",
    "    \n",
    "    user_prompt = f'Document: \"{text}\"'\n",
    "    \n",
    "    return call_aoai(aoai_client, aoai_model_name, system_prompt, user_prompt, 0.5, 4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 1: TABLE-ONLY\n",
    "\n",
    "markdown = \"\"\"\n",
    "\"Codificaci\\u00f3n ATOS\\n===\\n\\n||\\n| - |\\n| Gran P\\u00fablico - Servicios / Transmisi\\u00f3n de datos MS-Activa / GPRS - Servicios / E-moci\\u00f3n MS-Activa / Accesos / GPRS Empresas - Servicios/ Transmisi\\u00f3n de datos / GPRS |\\n| |\\n\"\n",
    "\"\"\"\n",
    "\n",
    "result = classify_with_gpt4o(markdown)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 2: TABLE-WITH-CONTEXT\n",
    "\n",
    "markdown = \"\"\"\n",
    "\"Plantillas\\n===\\n\\n||\\n| - |\\n| Patrocinio de Eventos Ante llamadas de clientes que indiquen estar interesados en que Telef\\u00f3nica M\\u00f3viles patrocine un evento que su empresa esta preparando, indicar que deben enviar por correo un dossier completo con todos los datos a: Att Francisco Garc\\u00eda del Pozo o Roc\\u00edo Vallejo-Nagera Telef\\u00f3nica M\\u00f3viles Espa\\u00f1a Distrito C, Edificio Sur 1, Planta 4 C/ Ronda de la Comunicaci\\u00f3n s/n 28050 Madrid |\\n| |\\n\"\n",
    "\"\"\"\n",
    "\n",
    "result = classify_with_gpt4o(markdown)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 3: TEXT-ONLY\n",
    "\n",
    "markdown = \"\"\"\n",
    "\"Esta llamada se codifica:\\n===\\n\\nRuta :\\n\\nGenerar Gesti\\u00f3n - Tramitaci\\u00f3n - Servicios - L\\u00ednea M\\u00faltiple - Multisim - Alta/Baja\\n\\nSe debe seleccionar la \\u00ednea que se va a modificar y se habilitar\\u00e1 el bot\\u00f3n \\\"Modificar\\\" Al acceder a la pantalla de modificaci\\u00f3n se debe seleccionar como \\\"Tipo de Actuaci\\u00f3n\\\": BAJA y \\\"Aceptar\\\"\\n\"\n",
    "\"\"\"\n",
    "\n",
    "result = classify_with_gpt4o(markdown)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify every txt file in the input directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chunk markdown files and write the chunks as files in the output directory\n",
    "input_dir = '../../data_out/markdown_files'\n",
    "markdown_contents = load_files(input_dir, '.txt')\n",
    "\n",
    "table_only=0\n",
    "table_with_content=0\n",
    "text_only=0\n",
    "for i, markdown_content in enumerate(markdown_contents):\n",
    "    print(f\"[{i + 1}]: title: {markdown_content['title']}\")\n",
    "\n",
    "    result = classify_with_gpt4o(markdown_content['content'])\n",
    "    print(f'\\t {result}')\n",
    "\n",
    "    if 'TABLE-ONLY' in result:\n",
    "        table_only+=1\n",
    "    elif 'TABLE-WITH-CONTEXT' in result:\n",
    "        table_with_content+=1\n",
    "    elif 'TEXT-ONLY' in result:\n",
    "        text_only+=1\n",
    "\n",
    "print(f'Total number of \"TABLE-ONLY\": {table_only}')\n",
    "print(f'Total number of \"TABLE-WITH-CONTEXT\": {table_only}')\n",
    "print(f'Total number of \"TEXT-ONLY\": {text_only}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
